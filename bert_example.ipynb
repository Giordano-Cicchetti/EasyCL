{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"red cat is meowing\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output1 = model(**encoded_input).last_hidden_state\n",
    "text = \"math lesson\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output2 = model(**encoded_input).last_hidden_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = torch.nn.functional.normalize(output1[0])\n",
    "output2 = torch.nn.functional.normalize(output2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9294, grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output1[0] @ output2[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from sentence_transformers) (4.45.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from sentence_transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from sentence_transformers) (2.4.1+cu124)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading scikit_learn-1.5.2-cp39-cp39-win_amd64.whl.metadata (13 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Using cached scipy-1.13.1-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from sentence_transformers) (0.25.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from sentence_transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.20.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence_transformers)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n",
      "Downloading scikit_learn-1.5.2-cp39-cp39-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 11.0/11.0 MB 76.9 MB/s eta 0:00:00\n",
      "Using cached scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sentence_transformers\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.13.1 sentence_transformers-3.1.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giord\\miniconda3\\envs\\weightedCL\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\giord\\miniconda3\\envs\\weightedCL\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('stsb-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"red cat is meowing\"\n",
    "embeddings1 = model.encode(['a man picking out a vehicle from the trailer', 'a web animation of a businessman', 'a video showing footage from sporting events', 'three men talking about their youtube channel and thanking their viewers', 'advertisement of seat basket', 'a video of a young man in a white shirt inviting his colleagues to join him', 'some peole are sitting in hall', 'a group discusses a man s outfit', 'a man is singing on stage to a huge audience he is holding a microphone', 'all persons are wearing bikini dresses and playing in sea', 'few barbie dolls are playing one doll puts shoe to other barbie these are used to play by a kid', 'a man prepares some food in the kitchen', 'several women in pink outfits and various other styles are standing and smiling', 'a lady describes about workout and exercises for women', 'a compilation of vine videos is shown', 'a lady talks into a megaphone'] , convert_to_tensor=True)\n",
    "text = \"red dog is barking\"\n",
    "embeddings2 = model.encode(text , convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1024])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([6.8731, 6.8731], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings1 = torch.nn.functional.normalize(embeddings1,dim=0)\n",
    "print(embeddings1.shape)\n",
    "embeddings2 = torch.nn.functional.normalize(embeddings2,dim=0)\n",
    "embeddings1 @ embeddings2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\giord\\miniconda3\\envs\\weightedcl\\lib\\site-packages (10.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 0.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 50.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 100.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 150.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 200.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 250.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 300.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 350.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 400.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 450.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 500.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 550.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 600.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 650.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 700.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 750.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 800.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 850.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 900.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 950.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1000.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1050.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1100.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1150.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1200.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1250.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1300.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1350.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1400.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1450.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1500.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1550.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1600.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1650.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1700.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1750.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1800.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1850.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1900.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 1950.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2000.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2050.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2100.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2150.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2200.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2250.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2300.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2350.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2400.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2450.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2500.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2550.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2600.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2650.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2700.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2750.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2800.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2850.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2900.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 2950.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3000.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3050.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3100.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3150.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3200.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3250.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3300.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3350.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3400.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3450.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3500.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3550.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3600.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3650.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3700.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3750.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3800.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3850.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3900.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 3950.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4000.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4050.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4100.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4150.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4200.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4250.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4300.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4350.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4400.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4450.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4500.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4550.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4600.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4650.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4700.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4750.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4800.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4850.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4900.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 4950.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5000.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5050.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5100.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5150.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5200.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5250.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5300.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5350.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5400.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5450.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5500.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5550.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5600.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5650.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5700.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5750.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5800.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5850.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5900.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 5950.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6000.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6050.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6100.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6150.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6200.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6250.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6300.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6350.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6400.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6450.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6500.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6550.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6600.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6650.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6700.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6750.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6800.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6850.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6900.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 6950.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7000.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7050.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7100.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7150.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7200.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7250.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7300.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7350.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7400.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7450.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7500.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7550.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7600.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7650.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7700.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7750.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7800.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7850.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7900.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 7950.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8000.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8050.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8100.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8150.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8200.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8250.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8300.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8350.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8400.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8450.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8500.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8550.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8600.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8650.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8700.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8750.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8800.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8850.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8900.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 8950.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9000.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9050.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9100.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9150.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9200.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9250.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9300.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9350.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9400.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9450.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9500.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9550.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9600.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9650.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9700.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9750.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9800.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9850.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9900.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 9950.png\n",
      "C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\\latent space at 10000.png\n",
      "GIF animata creata: C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA/output.gif\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def create_gif(image_folder, output_gif, duration=100):\n",
    "    \"\"\"\n",
    "    Crea una GIF animata a partire da una cartella di immagini PNG.\n",
    "\n",
    "    Args:\n",
    "    - image_folder (str): La cartella che contiene le immagini PNG.\n",
    "    - output_gif (str): Il percorso del file di output GIF.\n",
    "    - duration (int): La durata di ogni frame in millisecondi (default: 100ms).\n",
    "    \"\"\"\n",
    "    # Recupera tutte le immagini PNG dalla cartella specificata\n",
    "    images = []\n",
    "    def sort_files_by_modification_time(folder_path):\n",
    "        # Get all files in the specified folder\n",
    "        files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    \n",
    "        # Sort files based on modification time\n",
    "        files.sort(key=lambda x: os.path.getmtime(x))\n",
    "    \n",
    "        return files\n",
    "    \n",
    "    for filename in sort_files_by_modification_time(image_folder):#os.listdir(image_folder):\n",
    "        if filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(image_folder, filename)\n",
    "            print(img_path)\n",
    "            img = Image.open(img_path)\n",
    "            images.append(img)\n",
    "    \n",
    "    # Verifica che ci siano immagini da combinare\n",
    "    if not images:\n",
    "        raise ValueError(\"Non sono state trovate immagini PNG nella cartella specificata.\")\n",
    "\n",
    "    # Salva le immagini come GIF animata\n",
    "    images[0].save(\n",
    "        output_gif,\n",
    "        save_all=True,\n",
    "        append_images=images[1:],  # Immagini da aggiungere alla GIF\n",
    "        duration=duration,  # Durata di ogni frame\n",
    "        loop=0  # Numero di loop (0 per loop infinito)\n",
    "    )\n",
    "\n",
    "    print(f\"GIF animata creata: {output_gif}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Esempio di utilizzo\n",
    "create_gif(\"C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA\", \"C:/Users/giord/Desktop/Projects/WeightCL/Prove/TrueLossCentroidsCTCVCA/output.gif\", duration=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def compute_centroidsTest(text_embeddings, visual_embeddings, audio_embeddings):\n",
    "    \"\"\"\n",
    "    Computes the centroid for each pair of samples between text embeddings and visual/audio embeddings\n",
    "    by calculating the mean of the corresponding feature vectors across the two modalities.\n",
    "\n",
    "    Parameters:\n",
    "    - text_embeddings (torch.Tensor): Tensor of shape (batch_size1, feature_dim) representing text embeddings.\n",
    "    - visual_audio_embeddings (torch.Tensor): Tensor of shape (batch_size2, feature_dim) representing visual/audio embeddings.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Tensor of shape (batch_size1, batch_size2, feature_dim) representing the centroid for each pair.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get batch sizes\n",
    "    batch_size1 = text_embeddings.shape[0]   # For text embeddings\n",
    "    batch_size2 = visual_embeddings.shape[0]  # For visual/audio embeddings\n",
    "\n",
    "    # Compute centroids by averaging text and visual/audio embeddings\n",
    "    # Expand the dimensions to allow pairwise computation\n",
    "    text_expanded = text_embeddings.unsqueeze(1)  # Shape: [batch_size1, 1, feature_dim]\n",
    "    print(text_expanded.shape)\n",
    "    print(text_expanded)\n",
    "    visual_expanded = visual_embeddings.unsqueeze(0)  # Shape: [1, batch_size2, feature_dim]\n",
    "    print(visual_expanded.shape)\n",
    "    print(visual_expanded)\n",
    "    audio_expanded = audio_embeddings.unsqueeze(0)\n",
    "\n",
    "    # Compute the centroid by averaging the embeddings\n",
    "    \n",
    "    centroids = (text_expanded + visual_expanded + audio_expanded) / 3.0\n",
    "    #print(centroids)\n",
    "    print(centroids)\n",
    "\n",
    "    \n",
    "    centroid_norms = torch.norm(centroids, dim=-1)\n",
    "\n",
    "    #norm_condition = centroid_norms >= 0.5\n",
    "    #centroid_norms = torch.where(norm_condition, centroid_norms, torch.tensor(0.0))\n",
    "\n",
    "    return centroid_norms, centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3])\n",
      "tensor([[[0, 1, 1]],\n",
      "\n",
      "        [[0, 0, 1]]])\n",
      "torch.Size([1, 2, 3])\n",
      "tensor([[[0, 1, 0],\n",
      "         [1, 0, 1]]])\n",
      "tensor([[[0.0000, 0.6667, 0.6667],\n",
      "         [0.6667, 0.6667, 1.0000]],\n",
      "\n",
      "        [[0.0000, 0.3333, 0.6667],\n",
      "         [0.6667, 0.3333, 1.0000]]])\n",
      "tensor([[0.9428, 1.3744],\n",
      "        [0.7454, 1.2472]])\n",
      "tensor([[0.9428, 0.7454],\n",
      "        [1.3744, 1.2472]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[0,1,1],[0,0,1]])\n",
    "b=torch.tensor([[0,1,0],[1,0,1]])\n",
    "c=torch.tensor([[0,0,1],[1,1,1]])\n",
    "\n",
    "matrix_norm,centroids=compute_centroidsTest(a,b,c)\n",
    "print(matrix_norm)\n",
    "print(matrix_norm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8889, 1.1111],\n",
      "        [1.1111, 1.8889]])\n"
     ]
    }
   ],
   "source": [
    "print(centroids[0]@centroids[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[1.3744, 0.9428],\n",
       "        [1.2472, 0.7454]]),\n",
       "indices=tensor([[1, 0],\n",
       "        [1, 0]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_norm.sort(dim=-1,descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3729)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "a = torch.tensor([1,-1,-1]).float()\n",
    "target = torch.tensor([1,0,0]).float()\n",
    "F.cross_entropy(a, target, label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix:\n",
      "tensor([[-1.3026,  0.3969,  0.6831, -0.4572, -0.4039],\n",
      "        [-0.4150, -0.9352,  0.1681, -0.1742, -1.1731],\n",
      "        [ 1.3658, -0.4777,  0.2989, -0.8788, -1.5159],\n",
      "        [ 0.1417,  0.8148,  1.0215, -0.2499,  0.9693],\n",
      "        [ 0.7999, -0.2600,  0.1153, -1.0073, -0.8122]])\n",
      "\n",
      "New Matrix without Diagonal:\n",
      "tensor([[ 0.3969,  0.6831, -0.4572, -0.4039],\n",
      "        [-0.4150,  0.1681, -0.1742, -1.1731],\n",
      "        [ 1.3658, -0.4777, -0.8788, -1.5159],\n",
      "        [ 0.1417,  0.8148,  1.0215,  0.9693],\n",
      "        [ 0.7999, -0.2600,  0.1153, -1.0073]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a sample matrix of shape [n, n]\n",
    "n = 5\n",
    "matrix = torch.randn(n, n)\n",
    "\n",
    "# Print the original matrix\n",
    "print(\"Original Matrix:\")\n",
    "print(matrix)\n",
    "\n",
    "# Remove the diagonal\n",
    "# Create an index tensor for the rows and columns\n",
    "mask = torch.ones((n, n), dtype=torch.bool)  # Create a boolean mask of shape [n, n]\n",
    "mask.fill_diagonal_(False)                   # Set the diagonal to False\n",
    "\n",
    "# Use the mask to index the original matrix\n",
    "# Get only the non-diagonal elements\n",
    "non_diag_elements = matrix[mask].view(n , n-1 )\n",
    "\n",
    "# Print the new matrix\n",
    "print(\"\\nNew Matrix without Diagonal:\")\n",
    "print(non_diag_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_similarity_matrix():\n",
    "    # Define the number of items\n",
    "    n_items = 10\n",
    "\n",
    "    # Initialize an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((n_items, n_items))\n",
    "\n",
    "    # Define the two groups\n",
    "    group_1 = [0, 1, 2, 3, 4]  # Group 1 (0-4)\n",
    "    group_2 = [5, 6, 7, 8, 9]  # Group 2 (5-9)\n",
    "\n",
    "    # Fill the matrix with similarity values\n",
    "    for i in range(n_items):\n",
    "        for j in range(i, n_items):\n",
    "            if i == j:\n",
    "                similarity_matrix[i, j] = 1  # Perfect similarity with itself\n",
    "            elif (i in group_1 and j in group_1) or (i in group_2 and j in group_2):\n",
    "                similarity_matrix[i, j] = 0.8  # High similarity within the same group\n",
    "            else:\n",
    "                similarity_matrix[i, j] = 0  # Low similarity between groups\n",
    "\n",
    "            similarity_matrix[j, i] = similarity_matrix[i, j]  # Ensure symmetry\n",
    "\n",
    "    # Convert to torch tensor and move to GPU\n",
    "    similarity_matrix = torch.tensor(similarity_matrix).to('cuda')\n",
    "\n",
    "    # Print the raw similarity matrix\n",
    "    print(\"Raw Similarity Matrix:\")\n",
    "    print(similarity_matrix)\n",
    "\n",
    "    # If smoothing with sigmoid style\n",
    "    #similarity_matrix = 1 - (1 / (1 + torch.exp(-5 * (similarity_matrix))))  # Smoothing to get values between 0 and 1\n",
    "    #similarity_matrix = (1 / (1 + torch.exp(-5 * (similarity_matrix))))\n",
    "    print(\"Smoothing Applied (Sigmoid Style):\")\n",
    "    print(similarity_matrix)\n",
    "\n",
    "    # If linear decaying (if needed, you can uncomment this line)\n",
    "    # similarity_matrix = 1 - similarity_matrix\n",
    "\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Similarity Matrix:\n",
      "tensor([[1.0000, 0.8000, 0.8000, 0.8000, 0.8000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8000, 1.0000, 0.8000, 0.8000, 0.8000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8000, 0.8000, 1.0000, 0.8000, 0.8000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8000, 0.8000, 0.8000, 1.0000, 0.8000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8000, 0.8000, 0.8000, 0.8000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8000, 1.0000, 0.8000, 0.8000,\n",
      "         0.8000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8000, 0.8000, 1.0000, 0.8000,\n",
      "         0.8000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8000, 0.8000, 0.8000, 1.0000,\n",
      "         0.8000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         1.0000]], device='cuda:0', dtype=torch.float64)\n",
      "Smoothing Applied (Sigmoid Style):\n",
      "tensor([[1.0000, 0.8000, 0.8000, 0.8000, 0.8000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8000, 1.0000, 0.8000, 0.8000, 0.8000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8000, 0.8000, 1.0000, 0.8000, 0.8000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8000, 0.8000, 0.8000, 1.0000, 0.8000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8000, 0.8000, 0.8000, 0.8000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.8000, 0.8000, 0.8000,\n",
      "         0.8000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8000, 1.0000, 0.8000, 0.8000,\n",
      "         0.8000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8000, 0.8000, 1.0000, 0.8000,\n",
      "         0.8000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8000, 0.8000, 0.8000, 1.0000,\n",
      "         0.8000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8000, 0.8000, 0.8000, 0.8000,\n",
      "         1.0000]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = compute_similarity_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1636, 0.1339, 0.1339, 0.1339, 0.1339, 0.0602, 0.0602, 0.0602, 0.0602,\n",
       "         0.0602],\n",
       "        [0.1339, 0.1636, 0.1339, 0.1339, 0.1339, 0.0602, 0.0602, 0.0602, 0.0602,\n",
       "         0.0602],\n",
       "        [0.1339, 0.1339, 0.1636, 0.1339, 0.1339, 0.0602, 0.0602, 0.0602, 0.0602,\n",
       "         0.0602],\n",
       "        [0.1339, 0.1339, 0.1339, 0.1636, 0.1339, 0.0602, 0.0602, 0.0602, 0.0602,\n",
       "         0.0602],\n",
       "        [0.1339, 0.1339, 0.1339, 0.1339, 0.1636, 0.0602, 0.0602, 0.0602, 0.0602,\n",
       "         0.0602],\n",
       "        [0.0602, 0.0602, 0.0602, 0.0602, 0.0602, 0.1636, 0.1339, 0.1339, 0.1339,\n",
       "         0.1339],\n",
       "        [0.0602, 0.0602, 0.0602, 0.0602, 0.0602, 0.1339, 0.1636, 0.1339, 0.1339,\n",
       "         0.1339],\n",
       "        [0.0602, 0.0602, 0.0602, 0.0602, 0.0602, 0.1339, 0.1339, 0.1636, 0.1339,\n",
       "         0.1339],\n",
       "        [0.0602, 0.0602, 0.0602, 0.0602, 0.0602, 0.1339, 0.1339, 0.1339, 0.1636,\n",
       "         0.1339],\n",
       "        [0.0602, 0.0602, 0.0602, 0.0602, 0.0602, 0.1339, 0.1339, 0.1339, 0.1339,\n",
       "         0.1636]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "F.softmax(similarity_matrix,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.4869e-01, 8.7791e-02, 8.7791e-02, 8.7791e-02, 8.7791e-02, 2.9450e-05,\n",
       "         2.9450e-05, 2.9450e-05, 2.9450e-05, 2.9450e-05],\n",
       "        [8.7791e-02, 6.4869e-01, 8.7791e-02, 8.7791e-02, 8.7791e-02, 2.9450e-05,\n",
       "         2.9450e-05, 2.9450e-05, 2.9450e-05, 2.9450e-05],\n",
       "        [8.7791e-02, 8.7791e-02, 6.4869e-01, 8.7791e-02, 8.7791e-02, 2.9450e-05,\n",
       "         2.9450e-05, 2.9450e-05, 2.9450e-05, 2.9450e-05],\n",
       "        [8.7791e-02, 8.7791e-02, 8.7791e-02, 6.4869e-01, 8.7791e-02, 2.9450e-05,\n",
       "         2.9450e-05, 2.9450e-05, 2.9450e-05, 2.9450e-05],\n",
       "        [8.7791e-02, 8.7791e-02, 8.7791e-02, 8.7791e-02, 6.4869e-01, 2.9450e-05,\n",
       "         2.9450e-05, 2.9450e-05, 2.9450e-05, 2.9450e-05],\n",
       "        [2.9450e-05, 2.9450e-05, 2.9450e-05, 2.9450e-05, 2.9450e-05, 6.4869e-01,\n",
       "         8.7791e-02, 8.7791e-02, 8.7791e-02, 8.7791e-02],\n",
       "        [2.9450e-05, 2.9450e-05, 2.9450e-05, 2.9450e-05, 2.9450e-05, 8.7791e-02,\n",
       "         6.4869e-01, 8.7791e-02, 8.7791e-02, 8.7791e-02],\n",
       "        [2.9450e-05, 2.9450e-05, 2.9450e-05, 2.9450e-05, 2.9450e-05, 8.7791e-02,\n",
       "         8.7791e-02, 6.4869e-01, 8.7791e-02, 8.7791e-02],\n",
       "        [2.9450e-05, 2.9450e-05, 2.9450e-05, 2.9450e-05, 2.9450e-05, 8.7791e-02,\n",
       "         8.7791e-02, 8.7791e-02, 6.4869e-01, 8.7791e-02],\n",
       "        [2.9450e-05, 2.9450e-05, 2.9450e-05, 2.9450e-05, 2.9450e-05, 8.7791e-02,\n",
       "         8.7791e-02, 8.7791e-02, 8.7791e-02, 6.4869e-01]], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix = similarity_matrix / 0.1\n",
    "F.softmax(similarity_matrix,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weightedCL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
